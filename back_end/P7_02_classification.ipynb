{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P7_02_classification.ipynb","provenance":[],"collapsed_sections":["2_5GYA0vD8XL","ese_uwEcWDmA","GRVAC2SqGPSN","0ZdpGyoOcpnq","OsHeEDbASX6r","nIxkrBLQ_C-Y","wak84paR_HJF","5Ijwl1NGJCzB","4288fym__HS7","K--exfDtsaaU","G1zGw07MolK1","3HnzWelzr3q2","FU5Oeag-r7EP"],"toc_visible":true,"mount_file_id":"1jLqNudPRobS6zf7kDSqOIwrQJaZz0nei","authorship_tag":"ABX9TyMG1dSJa4loOxTyG2Qi6ypt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lZGYkyDMGNCZ"},"source":["# **I. Preparation**"]},{"cell_type":"markdown","metadata":{"id":"gG50vtN_CWvF"},"source":["## A. Imports"]},{"cell_type":"code","metadata":{"id":"tXoY9BqBhB3f","executionInfo":{"status":"ok","timestamp":1632931898580,"user_tz":-120,"elapsed":745,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["#!pip install lime"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"XbNC1cKdEg74"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","import seaborn as sns\n","import statistics as stat\n","import sys\n","\n","from importlib import reload\n","\n","#import lime\n","#import lime.lime_tabular\n","\n","from imblearn.over_sampling import SMOTE\n","\n","from scipy.stats import uniform\n","\n","from sklearn.dummy import DummyClassifier\n","\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import roc_curve\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from sklearn.svm import SVC\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","import xgboost as xgb\n","from xgboost import plot_importance\n","\n","# Constants\n","PATH = '/content/drive/My Drive/Colab Notebooks/ocr_data_scientist/P7 Modèle de scoring/'\n","\n","os.chdir(PATH)\n","if PATH not in sys.path:\n","    sys.path.append(PATH)\n","\n","import std_eda\n","import std_q7\n","import std_piechart\n","import std_pareto\n","import std_histogram\n","reload(std_eda)\n","reload(std_q7)\n","reload(std_piechart)\n","reload(std_pareto)\n","reload(std_histogram)\n","\n","# Options\n","sns.set_theme(style=\"darkgrid\")\n","pd.set_option('display.max_colwidth', None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oMyLevzUryS","executionInfo":{"status":"ok","timestamp":1632932170841,"user_tz":-120,"elapsed":1261,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}},"outputId":"e9abe4de-b64b-4831-9aa9-30fde6ac7362"},"source":["!pip install pipreqs\n","!pipreqs --force\n","!pip freeze > requirements.txt"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Successfully saved requirements file in /content/drive/My Drive/Colab Notebooks/ocr_data_scientist/P7 Modèle de scoring/requirements.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"2_5GYA0vD8XL"},"source":["## B. Uploads"]},{"cell_type":"code","metadata":{"id":"gBatTmR0D-UZ","executionInfo":{"status":"aborted","timestamp":1632931902928,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["train_df = pd.read_csv(PATH + 'data/app_train.csv', sep=',')\n","test_df = pd.read_csv(PATH + 'data/app_test.csv', sep=',')\n","cat_col = pd.read_csv(PATH + 'data/categorical_features.csv', sep=',')\n","app_train_df = pd.read_csv(PATH + 'data/application_train.csv', sep=',')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ese_uwEcWDmA"},"source":["## C. Inputs check"]},{"cell_type":"code","metadata":{"id":"VcDZrZvvdSq3","executionInfo":{"status":"aborted","timestamp":1632931902929,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["train_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_jcGqHnnDOJ","executionInfo":{"status":"aborted","timestamp":1632931902929,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["test_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwXHWypnm-EZ","executionInfo":{"status":"aborted","timestamp":1632931902930,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["#train_df.drop('SK_ID_CURR', axis=1, inplace=True)\n","#test_df.drop('SK_ID_CURR', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hvC1LfDG8aA","executionInfo":{"status":"aborted","timestamp":1632931902930,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["plt.pie(x=[train_df.shape[0], test_df.shape[0]],\n","        labels=['Train set', 'Test_set'],\n","        autopct=lambda x: round(x, 1),\n","        startangle=90,\n","        wedgeprops={'edgecolor':'k', 'linewidth': 1})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GRVAC2SqGPSN"},"source":["# **II. Modelisation**"]},{"cell_type":"markdown","metadata":{"id":"0ZdpGyoOcpnq"},"source":["## Settings"]},{"cell_type":"code","metadata":{"id":"BcmCxMd8cr_3","executionInfo":{"status":"aborted","timestamp":1632931902931,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Take a sample of the original dataframes\n","train_samp_df = train_df.sample(frac=0.02, random_state=1)\n","test_samp_df = test_df.sample(frac=0.02, random_state=1)\n","train_samp_df.set_index('SK_ID_CURR', inplace=True)\n","test_samp_df.set_index('SK_ID_CURR', inplace=True)\n","\n","# Set train and validation set \n","X = train_samp_df.drop('TARGET', axis=1)\n","targets = train_samp_df['TARGET']\n","\n","# Split the whole set\n","# The smallest part will be used to choose the best algorithm.\n","X_trainval, X_test, y_trainval, y_test = train_test_split(\n","    X,\n","    targets,\n","    test_size=0.2,\n","    random_state=1)\n","\n","# Split the trainval set\n","# The smallest part will be used for the validation phase.\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_trainval,\n","    y_trainval,\n","    test_size=0.2,\n","    random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsHeEDbASX6r"},"source":["## Fonctions"]},{"cell_type":"code","metadata":{"id":"8kV0HtGEr6zg","executionInfo":{"status":"aborted","timestamp":1632931902931,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["def split_oversample_fit(X, y, model):\n","    '''\n","    Perform split, oversampling and fitting on the given X and y sets\n","    '''\n","    # Train / test split\n","    X_train, X_val, y_train, y_val = train_test_split(X,\n","                                                      y,\n","                                                      test_size=0.2,\n","                                                      random_state=1)\n","    # Oversampling\n","    X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n","    X_resampled = pd.DataFrame(data=X_resampled,\n","                               columns=X.columns)\n","    #X_resampled['TARGET'] = pd.Series(y_resampled)\n","    # Fit the model\n","    model.fit(X_resampled, y_resampled)\n","\n","    return model, X_val, y_val\n","\n","\n","def class_model_perf(X, targets, model):\n","    '''\n","    Designed for a binary classification, two categories in total.\n","    Important: the model must be already instantiated.\n","    '''\n","\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","\n","    # Accuracy\n","    accuracy = round(model.score(X_val, y_val), 3)\n","    \n","    # Confusion matrix elements\n","    y_pred = model.predict(X_val)\n","    # Get the false predictions\n","    pred_dict = dict(pd.Series(y_val - y_pred).value_counts())\n","    if -1.0 in pred_dict.keys():\n","        n_FP = pred_dict[-1.0]\n","    else:\n","        n_FP = 0\n","    if 1.0 in pred_dict.keys():\n","        n_FN = pred_dict[1.0]\n","    else:\n","        n_FN = 0\n","    # Get the true predictions\n","    temp_dict = dict(pd.Series(2 * y_val - y_pred).value_counts())\n","    if 1.0 in temp_dict.keys():\n","        n_TP = temp_dict[1.0]\n","    else:\n","        n_TP = 0\n","    \n","    try:\n","        # Precision\n","        precision = round(n_TP / (n_TP + n_FP), 4)\n","\n","        # Recall\n","        recall = round(n_TP / (n_TP + n_FN), 4)\n","    except ZeroDivisionError:\n","        return 'n_FP: {}, n_FN: {}, n_TP: {}.'.format(n_FP, n_FN, n_TP)\n","\n","    # f1 score\n","    f1 = round(f1_score(y_val, y_pred), 4)\n","\n","    return 'Accuracy: {}, Precision: {}, Recall: {}, f1-score: {}'.format(\n","        accuracy, precision, recall, f1)\n","\n","\n","def list_sample(my_list, chunk):\n","    '''\n","    Let a list be given, we select every 'chunk' element.\n","    Return a list of the selected elements.\n","    '''\n","    y = zip(*[iter(my_list)]*chunk)\n","    return [element[0] for element in y]\n","\n","\n","def plot_precision_recall_curve(model, X, targets, chunk=1):\n","    '''\n","\n","    '''\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    \n","    precision, recall, threshold = precision_recall_curve(\n","        y_val,\n","        model.predict_proba(X_val)[:, 1])\n","    f1_score = 2 * precision * recall / (precision + recall)\n","    # In the cas of overlapping points, select a sample of the lists\n","    precision = list_sample(precision, chunk)\n","    precision = np.array(precision)\n","    recall = list_sample(recall, chunk)\n","    recall = np.array(recall)\n","    f1_score = list_sample(f1_score, chunk)\n","    f1_score = np.array(f1_score)\n","    max_f1 = round(max(f1_score), 3)\n","\n","    plt.figure(figsize=(8, 8))\n","    plt.xlabel('Precision')\n","    plt.ylabel('Recall')\n","    close_default = np.argmin(np.abs(threshold - 0.5))\n","    plt.scatter(precision,\n","                recall,\n","                s=f1_score*2000,\n","                c=f1_score,\n","                cmap='Reds_r',\n","                edgecolors='k',\n","                alpha=0.5,\n","                label='Max f1_score: {}'.format(max_f1))\n","    plt.plot(precision[close_default//chunk-1],\n","            recall[close_default//chunk-1],\n","            '^',\n","            c='k',\n","            markersize=10,\n","            label='Threshold: 0.5',\n","            fillstyle='none',\n","            mew=2)\n","    # ADDITIONAL curves\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    # Line of equation y = x\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.legend(loc='best')\n","    plt.axis('square')\n","\n","\n","# Faire en sorte que targets et y_pred puissent être soustrait l'un à l'autre \n","# quelque soit leur type\n","\n","def check_prediction_costs():\n","    '''\n","    1. Check inputs of prediction_costs.\n","    2. \n","    '''\n","\n","\n","def prediction_costs(model, X, targets, y_pred=None):\n","    '''\n","    Return the sum of: \n","    - the cost of false positives,\n","    - the cost of false negatives.\n","    '''\n","    # Add the prediction errors to the original dataframe\n","    if type(y_pred) in [list, type(pd.DataFrame()), type(pd.Series())]:\n","        y_pred = np.array(y_pred)\n","    if not y_pred.any():\n","        y_pred = model.predict(X)\n","    targets = np.array(targets)\n","    targets = targets.reshape((-1,1))\n","    y_pred = y_pred.reshape((-1,1))\n","    X['Prediction error'] = targets - y_pred\n","    # Create a new feature, multiplying the difference by a money feature.\n","    # This will be choosen based on feature importances.\n","    # FP costs\n","    # log_AMT_ANNUITY_prev: Annuity of previous application\n","    # AMT_CREDIT_SUM_DEBT: Current debt on Credit Bureau credit.\n","    # Although useful, it is absent of test set, thus cannot be used. \n","    FP_list = []\n","    for i, row in X.iterrows():\n","        if X['Prediction error'].loc[i] == -1:\n","            FP_list.append(-X['Prediction error'].loc[i] *\n","                           X['log AMT ANNUITY prev'].loc[i])\n","    FP_sum = sum(FP_list)\n","    # FN costs\n","    # log_AMT_ANNUITY: Loan annuity\n","    FN_list = []\n","    for i, row in X.iterrows():\n","        if X['Prediction error'].loc[i] == 1:\n","            FN_list.append(X['Prediction error'].loc[i] *\n","                           X['log AMT ANNUITY'].loc[i])\n","    FN_sum = sum(FN_list)\n","    # Remove the temporary column from X\n","    X.drop('Prediction error', axis=1, inplace=True)\n","\n","    return FP_sum + FN_sum\n","\n","\n","def costs_estimation(model, X, targets, chunk=1):\n","    '''\n","    Evaluate the cost for different values of threshold\n","    '''\n","    # Prepare for y_pred computation\n","    pred_proba = model.predict_proba(X)\n","    predict = [element[1] for element in pred_proba]\n","    precision, recall, thresholds = precision_recall_curve(\n","        targets,\n","        model.predict_proba(X)[:, 1])\n","    \n","    # In the cas of overlapping points, select a sample of the lists\n","    precision = list_sample(precision, chunk)\n","    precision = np.array(precision)\n","    recall = list_sample(recall, chunk)\n","    recall = np.array(recall)\n","    thresholds = list_sample(thresholds, chunk)\n","    thresholds = np.array(thresholds)\n","\n","    # Evaluate costs for different values of threshold\n","    y_costs = []\n","    for threshold in list(thresholds):\n","        # Compute y_pred\n","        y_pred = []\n","        for element in predict:\n","            if element >= threshold:\n","                y_pred.append(1)\n","            else:\n","                y_pred.append(0)\n","        # Compute the costs\n","        y_costs.append(prediction_costs(model,\n","                                        X,\n","                                        targets,\n","                                        y_pred))\n","\n","    # Set the 3 lists at the same size\n","    precision = list(precision)\n","    recall = list(recall)\n","    thresholds = list(thresholds)\n","    temp_min = min(len(precision), len(recall), len(thresholds), len(y_costs))\n","    precision = precision[:temp_min]\n","    recall = recall[:temp_min]\n","    thresholds = thresholds[:temp_min]\n","    y_costs = y_costs[:temp_min]\n","    return precision, recall, y_costs, thresholds\n","\n","\n","def costs_curve(model, X, targets, chunk=1):\n","    '''\n","    Display the precision / recall curve, the size and color of each point\n","    representing its corresponding cost.\n","    '''\n","    \n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    # get the \n","    precision, recall, y_costs, thresholds = costs_estimation(model,\n","                                                              X_val,\n","                                                              y_val,\n","                                                              chunk=chunk)\n","    # Plot the graph\n","    plt.figure(figsize=(8, 8))\n","    plt.xlabel('Precision')\n","    plt.ylabel('Recall')\n","    thresholds = [element - 0.5 for element in thresholds]\n","    close_default = np.argmin(np.abs(thresholds))\n","    plt.scatter(precision,\n","                recall,\n","                s=y_costs,\n","                c=y_costs,\n","                cmap='Reds',\n","                edgecolors='k',\n","                alpha=0.5)\n","    plt.plot(precision[close_default//chunk-1],\n","            recall[close_default//chunk-1],\n","            '^',\n","            c='k',\n","            markersize=10,\n","            label='Threshold: 0.5',\n","            fillstyle='none',\n","            mew=2)\n","    # Line of equation y = x\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.legend(loc='best')\n","    plt.axis('square')\n","\n","\n","def plot_ROC_curve(model, X, targets):\n","    '''\n","\n","    '''\n","    fpr, tpr, threshold = roc_curve(targets,\n","                                    model.predict_proba(X)[:, 1])\n","    plt.xlabel('FPR')\n","    plt.ylabel('TPR (recall)')\n","    plt.title('ROC curve')\n","    # Line of equation y = x\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.axis('square')\n","    plt.plot(fpr, tpr)\n","\n","\n","def lowest_costs_param(model, X, targets):\n","    '''\n","    Return the lowest cost obtained.\n","    '''\n","    precision, recall, costs, thresholds = costs_estimation(model,\n","                                                            X,\n","                                                            targets)\n","    precision = [round(element, 2) for element in precision]\n","    recall = [round(element, 2) for element in recall]\n","    thresholds = [round(element, 3) for element in thresholds]\n","    costs = [round(element, 3) for element in costs]\n","    df = pd.DataFrame({'Precision':precision,\n","                    'Recall':recall,\n","                    'Cost':costs,\n","                    'Threshold':thresholds})\n","    df.sort_values(by='Cost', inplace=True)\n","    return dict(df.iloc[0])\n","\n","\n","def plot_feature_importances(model, X, n_feat):\n","    '''\n","    Display a histogram of the feature importances, sorted from the most\n","    important to the least important.\n","    '''\n","    feature_importances = pd.Series(model.feature_importances_,\n","                                    index=X.columns)\n","    feature_importances = feature_importances.sort_values(ascending=False)\n","    feature_importances = feature_importances[:n_feat]\n","    plt.bar(range(len(feature_importances)),\n","            feature_importances,\n","            edgecolor='k')\n","\n","\n","def feature_importance_cumsum(model, df, filter=None):\n","    '''\n","\n","    '''\n","    importances = model.feature_importances_\n","    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n","                 axis=0)\n","    forest_importances = pd.Series(importances,\n","                                   index=X.columns)\n","    forest_importances.sort_values(ascending=False,\n","                                   inplace=True)\n","    if filter:\n","        # Sort and filter the first 10% \n","        ratio = len(forest_importances)//10\n","        forest_importances = forest_importances[:ratio]\n","        forest_importances\n","    plt.plot(forest_importances.cumsum())\n","\n","\n","def most_important_features(model, X, n_feat=6):\n","    '''\n","    Display the n most important feature.\n","    '''\n","    feature_importances = pd.Series(model.feature_importances_,\n","                                    index=X.columns)\n","    feature_importances = feature_importances.sort_values(ascending=False)\n","    feature_importances = feature_importances[:n_feat]\n","    return feature_importances\n","\n","\n","def plot_important_features(feature_importances):\n","    '''\n","    \n","    '''\n","    plt.barh(feature_importances.index,\n","             feature_importances)\n","\n","\n","def prediction_with_threshold(predict_proba, threshold=0.5):\n","    '''\n","    \n","    '''\n","    # Select positive prediction\n","    predict_proba = predict_proba[:, 1]\n","    # Form the y_pred\n","    y_pred = []\n","    for element in predict_proba:\n","        if element >= threshold:\n","            y_pred.append(1)\n","        else:\n","            y_pred.append(0)\n","    y_pred = pd.Series(data=y_pred)\n","    return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nIxkrBLQ_C-Y"},"source":["## A. Dummy classifier"]},{"cell_type":"code","metadata":{"id":"8HneCt6_1yCK","executionInfo":{"status":"aborted","timestamp":1632931902931,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Instanciation\n","model = DummyClassifier(strategy='constant', constant=1)\n","# Scores\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wak84paR_HJF"},"source":["## B. Decision tree"]},{"cell_type":"code","metadata":{"id":"LPFCqI4F_Pdi","executionInfo":{"status":"aborted","timestamp":1632931902931,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Instanciation\n","model = DecisionTreeClassifier(max_depth=2)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Ijwl1NGJCzB"},"source":["## C. Logistic regression"]},{"cell_type":"code","metadata":{"id":"qYv199nAJDT1","executionInfo":{"status":"aborted","timestamp":1632931902932,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Accuracy score\n","model = LogisticRegression(C=0.1)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4288fym__HS7"},"source":["## D. SVC"]},{"cell_type":"code","metadata":{"id":"a_YN995I_P0Q","executionInfo":{"status":"aborted","timestamp":1632931902932,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["if False:\n","    # Instanciation\n","    model = SVC(gamma=0.05)\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyhma-mO_QGr"},"source":["## E. Random forest"]},{"cell_type":"code","metadata":{"id":"W3fbBQB2_XGa","executionInfo":{"status":"aborted","timestamp":1632931902932,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Instanciation\n","model = RandomForestClassifier(n_estimators=100,\n","                               random_state=0,\n","                               max_features=2)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7m1W6csLXGq","executionInfo":{"status":"aborted","timestamp":1632931902933,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYR5TDdDAvon","executionInfo":{"status":"aborted","timestamp":1632931902933,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Costs curve\n","if True:\n","    costs_curve(model, X, targets, chunk=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRsnIFnmHcvg","executionInfo":{"status":"aborted","timestamp":1632931902933,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWAnwjyCZkjW","executionInfo":{"status":"aborted","timestamp":1632931902934,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances\n","if True:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_aiNsHr8J9Ok","executionInfo":{"status":"aborted","timestamp":1632931902934,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TubExPZbZkUz","executionInfo":{"status":"aborted","timestamp":1632931902934,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: first ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSgZoJk9Ms-W","executionInfo":{"status":"aborted","timestamp":1632931902935,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# ROC curve\n","if True:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ZoCPqxH99XG"},"source":["## F. GradientBoosting"]},{"cell_type":"code","metadata":{"id":"_92yrB09-Ta6","executionInfo":{"status":"aborted","timestamp":1632931902935,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["if True:\n","    # Instanciation\n","    model = GradientBoostingClassifier()\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LD2TyRhTKzbI","executionInfo":{"status":"aborted","timestamp":1632931902935,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKp44h20FZYP","executionInfo":{"status":"aborted","timestamp":1632931902936,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Costs curve\n","if True:\n","    costs_curve(model, X, targets, chunk=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QYKkwJIpoow","executionInfo":{"status":"aborted","timestamp":1632931902936,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG492qMQXTsD","executionInfo":{"status":"aborted","timestamp":1632931902936,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances\n","if True:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGEW_xz_XTpp","executionInfo":{"status":"aborted","timestamp":1632931902936,"user_tz":-120,"elapsed":26,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pn_L0CukaSbk","executionInfo":{"status":"aborted","timestamp":1632931902937,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: first ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eORmWcjzRzvI","executionInfo":{"status":"aborted","timestamp":1632931902937,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# ROC curve\n","if True:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Rqli5Ni-Rfq"},"source":["## G. XGBoost"]},{"cell_type":"code","metadata":{"id":"KJX8t87X-Tyn","executionInfo":{"status":"aborted","timestamp":1632931902937,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["if True:\n","    # Instanciation\n","    model = xgb.XGBClassifier()\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHp2kEBzR1QG","executionInfo":{"status":"aborted","timestamp":1632931902938,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2B8ZvzHBFVzm","executionInfo":{"status":"aborted","timestamp":1632931902938,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Costs curve\n","if True:\n","    costs_curve(model, X, targets, chunk=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8od1shxgDeSs","executionInfo":{"status":"aborted","timestamp":1632931902939,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KpetlMjVM7R","executionInfo":{"status":"aborted","timestamp":1632931902939,"user_tz":-120,"elapsed":25,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances\n","if True:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJRZaUuTWnPk","executionInfo":{"status":"aborted","timestamp":1632931902939,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhdIwzunYMas","executionInfo":{"status":"aborted","timestamp":1632931902940,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Feature importances: most important ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrpHKuogR1Ng","executionInfo":{"status":"aborted","timestamp":1632931902940,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# ROC curve\n","if True:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K--exfDtsaaU"},"source":["# **III. Algorithm optimisation**"]},{"cell_type":"markdown","metadata":{"id":"G1zGw07MolK1"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"sR5L39engzp4"},"source":["As XGBoost has been chosen, we need now to define the **objective function**.\n","\n","Objective function = Training loss + Regularization.\n","The general principle is that we want a *simple* and *predictive* model.\n","\n","**Training loss**\n","*   measures how predictive our model is with respect to the training data\n","*   obtained through prediction_costs\n","\n","**Regularization**\n","*   controls the complexity of the model,  helps to avoid overfitting\n","*   \n","\n","**Challenges ahead**\n","*   get similar performances on train set & test set\n","*   taking into account a *balanced* train set and an *imbalanced* test set.\n","*   big computation time (150 sec for a single 3-fold cross validation)"]},{"cell_type":"code","metadata":{"id":"kNwAxxfvg2Bg","executionInfo":{"status":"aborted","timestamp":1632931902940,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Create a specific cost score\n","# cost_score = make_scorer(prediction_costs_for_cv, greater_is_better=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3HnzWelzr3q2"},"source":["## A. GridSearchCV"]},{"cell_type":"code","metadata":{"id":"EhH4DoNAacjb","executionInfo":{"status":"aborted","timestamp":1632931902940,"user_tz":-120,"elapsed":23,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["def CV_cost(X, targets, eta, gamma, max_depth, reg_lambda, n_splits=3):\n","    '''\n","    Perform a cross validation on train set and returns:\n","    - the average cost on train set\n","    - the average cost on test set\n","    '''\n","    # Guarantee a k-fold cross validation\n","    skfold = StratifiedKFold(n_splits=n_splits)\n","    # Create the list of costs for each fold\n","    train_costs = []\n","    test_costs = []\n","    for fold, (trainval_idx, test_idx) in enumerate(skfold.split(X,targets),1):\n","        # Form trainval and test sets\n","        X_trainval = X.iloc[trainval_idx]\n","        y_trainval = targets.iloc[trainval_idx]\n","        X_test = X.iloc[test_idx]\n","        y_test = targets.iloc[test_idx]\n","        # Rebalance the dataset with SMOTE oversampling\n","        sm = SMOTE()\n","        X_trainval_oversampled, y_trainval_oversampled = sm.fit_sample(\n","            X_trainval,\n","            y_trainval)\n","        \n","        X_trainval_oversampled = pd.DataFrame(\n","            data=X_trainval_oversampled,\n","            columns=X_trainval.columns)\n","        y_trainval_oversampled = pd.DataFrame(\n","            data = y_trainval_oversampled,\n","            columns=['Targets'])\n","        # Instantiate and fit the model to trainval set\n","        model = xgb.XGBClassifier(random_state=0,\n","                                  eta=eta,\n","                                  gamma=gamma,\n","                                  max_depth=max_depth,\n","                                  reg_lambda=reg_lambda)\n","        model.fit(X_trainval_oversampled,\n","                  y_trainval_oversampled)\n","        # Get the threshold giving the lowest cost\n","        threshold = lowest_costs_param(model,\n","                                       X_trainval_oversampled,\n","                                       y_trainval_oversampled)['Threshold']\n","        # Get predictions on test set\n","        train_y_pred = prediction_with_threshold(\n","            model.predict_proba(X_trainval_oversampled),\n","            threshold)\n","        test_y_pred = prediction_with_threshold(\n","            model.predict_proba(X_test),\n","            threshold)\n","        # Display the results\n","        train_costs.append(prediction_costs(model,\n","                                            X_trainval_oversampled,\n","                                            y_trainval_oversampled,\n","                                            train_y_pred))\n","        test_costs.append(prediction_costs(model,\n","                                           X_test,\n","                                           y_test,\n","                                           test_y_pred))\n","    # Computation of the average values\n","    train_cost_avg = stat.mean(train_costs)\n","    test_cost_avg = stat.mean(test_costs)\n","\n","    return train_cost_avg, test_cost_avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXatz877sgGF","executionInfo":{"status":"aborted","timestamp":1632931902941,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["def CV_optimisation():\n","    '''\n","\n","    '''\n","    # Set parameters range\n","    eta_list = [0.1] # learning_rate\n","    gamma_list = [0.05, 0.1, 0.2] # regularization term\n","    max_depth_list = [2, 3, 4]\n","    lambda_list = [1.2]\n","    # alpha=[], # may be not used if tuning lambda is enough\n","    scale_pos_weight = 1 # because of high class imbalance\n","    objective = 'binary:logistic' # for classification problems with probability\n","    num_feature = 100 # thanks to feature importance evaluation\n","\n","    scores_df = pd.DataFrame(columns=['eta',\n","                                      'gamma',\n","                                      'max_depth',\n","                                      'reg_lambda',\n","                                      'Train cost',\n","                                      'Test cost'])\n","\n","    for i, eta in enumerate(eta_list):\n","        row = {}\n","        row['eta'] = eta\n","        print('- ', i)\n","        for ii, gamma in enumerate(gamma_list):\n","            row['gamma'] = gamma\n","            print('--- ', ii)\n","            for iii, max_depth in enumerate(max_depth_list):\n","                row['max_depth'] = max_depth\n","                print('------ ', iii)\n","                for iv, reg_lambda in enumerate(lambda_list):\n","                    row['reg_lambda'] = reg_lambda\n","                    print('--------- ', iv)\n","                    train_cost_avg, test_cost_avg = CV_cost(\n","                        X, targets,\n","                        eta, gamma, max_depth, reg_lambda)\n","                    row['Train cost'] = train_cost_avg\n","                    row['Test cost'] = test_cost_avg\n","                    scores_df.loc[scores_df.shape[0]] = row\n","    # Post-processing\n","    scores_df.sort_values(by='Test cost', ascending=True, inplace = True)\n","    scores_df.to_csv(PATH + 'data/' + 'scores.csv')\n","    # Plot\n","    train_list = list(scores_df['Train cost'])\n","    test_list = list(scores_df['Test cost'])\n","\n","    plt.title('Train / test performances')\n","    plt.ylabel('Cost')\n","    plt.plot(train_list, label='Train')\n","    plt.plot(test_list, label='Test')\n","    plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hr4DZ8kWm-Hv","executionInfo":{"status":"aborted","timestamp":1632931902941,"user_tz":-120,"elapsed":23,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["def plot_DoE():\n","    '''\n","    Plot design of experiment results\n","    '''\n","    eta_df = scores_df.groupby(by=['eta']).mean()['Test cost']\n","    eta_df.index = ['min', 'med', 'max']\n","    gamma_df = scores_df.groupby(by=['gamma']).mean()['Test cost']\n","    gamma_df.index = ['min', 'med', 'max']\n","    max_depth_df = scores_df.groupby(by=['max_depth']).mean()['Test cost']\n","    max_depth_df.index = ['min', 'med', 'max']\n","    reg_lambda_df = scores_df.groupby(by=['reg_lambda']).mean()['Test cost']\n","    reg_lambda_df.index = ['min', 'med', 'max']\n","\n","    plt.title('Step 3')\n","    plt.xlabel('Parameter values')\n","    plt.ylabel('Test score')\n","    plt.plot(eta_df, label='eta')\n","    plt.plot(gamma_df, label='gamma', color='orange')\n","    plt.plot(max_depth_df, label='max_depth', color='green')\n","    plt.plot(reg_lambda_df, label='reg_lambda', color='red')\n","    plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FU5Oeag-r7EP"},"source":["## B. RandomizedSearchCV"]},{"cell_type":"code","metadata":{"id":"L-_P_YZvotps","executionInfo":{"status":"aborted","timestamp":1632931902941,"user_tz":-120,"elapsed":23,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["if False:\n","    # Set parameters range\n","    RS_parameters = {'n_estimators':[80, 120],\n","                    'max_depth':[3, 7],\n","                    'max_features':[int(math.sqrt(X_train.shape[0])) + 20,\n","                                    int(math.sqrt(X_train.shape[0])) - 20],\n","                    'min_samples_split':[3, 7],\n","                    'min_samples_leaf':[1, 3],\n","                    'bootstrap':[True, False]}\n","    # Cross validation\n","    rdm = RandomizedSearchCV(model,\n","                            RS_parameters,\n","                            cv=5,\n","                            n_iter=10,\n","                            scoring=cost_score)\n","    # Fit the model\n","    rdm.fit(X_train, y_train)\n","    # Get the best parameters combination\n","    rdm_best = rdm.best_estimator_\n","    # Get the lowest cost\n","    cost = prediction_costs_for_cv(y_val, rdm_best.predict(X_val))\n","    cost = round(cost, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fasuEW5v5PiB"},"source":["# **IV. pickle optimised model**"]},{"cell_type":"code","metadata":{"id":"pG4Qk9FP5V0R","executionInfo":{"status":"aborted","timestamp":1632931902942,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Set train and validation set \n","X = train_df.drop('TARGET', axis=1)\n","targets = train_df['TARGET']\n","\n","# Oversampling the whole train set\n","sm = SMOTE()\n","X_train_oversampled, y_train_oversampled = sm.fit_sample(X,\n","                                                         targets)\n","X_train_oversampled = pd.DataFrame(data=X_train_oversampled,\n","                                   columns=X.columns)\n","y_train_oversampled = pd.DataFrame(data = y_train_oversampled,\n","                                   columns=['Targets'])\n","\n","# Set index\n","X_train_oversampled.drop('SK_ID_CURR', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyVi9DXa2Wnj","executionInfo":{"status":"aborted","timestamp":1632931902942,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["X_train_oversampled.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1x0FzOOP7YFZ","executionInfo":{"status":"aborted","timestamp":1632931902942,"user_tz":-120,"elapsed":24,"user":{"displayName":"Benoît DELORME","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03178733258717085125"}}},"source":["# Instantiate and fit the model to train set\n","model = xgb.XGBClassifier(random_state=0,\n","                          eta=0.1,\n","                          gamma=0.2,\n","                          max_depth=4,\n","                          reg_lambda=1.2,\n","                          scale_pos_weight = 1,\n","                          objective = 'binary:logistic',\n","                          num_feature = 100)\n","model.fit(X_train_oversampled.values,\n","          y_train_oversampled.values)\n","# Pickle and save\n","#pickle.dump(model, open( \"fitted_xgb.pkl\", \"wb\" ))\n","# After recommandations read on:\n","# https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n","model.save_model('fitted_xgb.pkl')"],"execution_count":null,"outputs":[]}]}