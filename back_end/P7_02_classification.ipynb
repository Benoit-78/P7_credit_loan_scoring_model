{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P7_02_classification.ipynb","provenance":[],"collapsed_sections":["lZGYkyDMGNCZ","2_5GYA0vD8XL","ese_uwEcWDmA","GRVAC2SqGPSN","OsHeEDbASX6r","nIxkrBLQ_C-Y","wak84paR_HJF","5Ijwl1NGJCzB","4288fym__HS7","yyhma-mO_QGr","_ZoCPqxH99XG","0Rqli5Ni-Rfq"],"toc_visible":true,"mount_file_id":"1jLqNudPRobS6zf7kDSqOIwrQJaZz0nei","authorship_tag":"ABX9TyM+/BLgy+J7NTeoO9oJylTI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lZGYkyDMGNCZ"},"source":["# **I. Preparation**"]},{"cell_type":"markdown","metadata":{"id":"gG50vtN_CWvF"},"source":["## A. Imports"]},{"cell_type":"code","metadata":{"id":"tXoY9BqBhB3f"},"source":["#!pip install lime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbNC1cKdEg74","executionInfo":{"status":"ok","timestamp":1630593102115,"user_tz":-120,"elapsed":2500,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"2bd4413f-6fd6-4c31-e82c-a7c4704d5eb9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","import seaborn as sns\n","import statistics as stat\n","import sys\n","\n","from importlib import reload\n","\n","#import lime\n","#import lime.lime_tabular\n","\n","from imblearn.over_sampling import SMOTE\n","\n","from scipy.stats import uniform\n","\n","from sklearn.dummy import DummyClassifier\n","\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import roc_curve\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from sklearn.svm import SVC\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","import xgboost as xgb\n","from xgboost import plot_importance\n","\n","# Constants\n","PATH = '/content/drive/My Drive/Colab Notebooks/ocr_data_scientist/P7 Modèle de scoring/'\n","\n","os.chdir(PATH)\n","if PATH not in sys.path:\n","    sys.path.append(PATH)\n","\n","import std_eda\n","import std_q7\n","import std_piechart\n","import std_pareto\n","import std_histogram\n","reload(std_eda)\n","reload(std_q7)\n","reload(std_piechart)\n","reload(std_pareto)\n","reload(std_histogram)\n","\n","# Options\n","sns.set_theme(style=\"darkgrid\")\n","pd.set_option('display.max_colwidth', None)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"FMMVhpuOM368","executionInfo":{"status":"ok","timestamp":1630593108168,"user_tz":-120,"elapsed":1718,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}}},"source":["!pip freeze > requirements.lock.txt"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2_5GYA0vD8XL"},"source":["## B. Uploads"]},{"cell_type":"code","metadata":{"id":"gBatTmR0D-UZ","executionInfo":{"status":"ok","timestamp":1630593137705,"user_tz":-120,"elapsed":26685,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}}},"source":["train_df = pd.read_csv(PATH + 'data/app_train.csv', sep=',')\n","test_df = pd.read_csv(PATH + 'data/app_test.csv', sep=',')\n","cat_col = pd.read_csv(PATH + 'data/categorical_features.csv', sep=',')\n","app_train_df = pd.read_csv(PATH + 'data/application_train.csv', sep=',')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ese_uwEcWDmA"},"source":["## C. Inputs check"]},{"cell_type":"code","metadata":{"id":"VcDZrZvvdSq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571582256,"user_tz":-120,"elapsed":15,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"c845a568-507f-4192-bf42-028d35ea35dd"},"source":["train_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(307508, 306)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"j_jcGqHnnDOJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571582256,"user_tz":-120,"elapsed":13,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"4bbd703e-5cfa-4d8d-a23f-94f977423d28"},"source":["test_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48744, 305)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"kwXHWypnm-EZ"},"source":["#train_df.drop('SK_ID_CURR', axis=1, inplace=True)\n","#test_df.drop('SK_ID_CURR', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hvC1LfDG8aA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571582257,"user_tz":-120,"elapsed":10,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"b6f91888-b68a-4fbe-c8ff-91a75b502e4c"},"source":["plt.pie(x=[train_df.shape[0], test_df.shape[0]],\n","        labels=['Train set', 'Test_set'],\n","        autopct=lambda x: round(x, 1),\n","        startangle=90,\n","        wedgeprops={'edgecolor':'k', 'linewidth': 1})"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([<matplotlib.patches.Wedge at 0x7f34cab30690>,\n","  <matplotlib.patches.Wedge at 0x7f34cab30f10>],\n"," [Text(-0.45840470672487627, -0.9999325601521737, 'Train set'),\n","  Text(0.4584047067248764, 0.9999325601521736, 'Test_set')],\n"," [Text(-0.25003893094084156, -0.5454177600830038, '86.3'),\n","  Text(0.2500389309408416, 0.5454177600830037, '13.7')])"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVeLG8e9MkkkyyaT3kB4SinSkhiqCCCiINEFkUYR1XQWs2Na2FrCwgH1RFEXpLii4IgJSYwGkJqQQkpBCkknPJNPu7w9WfhZASjLnTnI+z7PPIpnc807IO/fOnXPv0SiKoiBJkupoRQeQJOn8ZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVkOSVJpWQ5JUmlZDklSaVcRQeQWpZx48ZhNpuxWCzk5OTQunVrANq1a8eLL754SdtITU3FYrGQkpLS6PkWL17MzJkz0el0jb7ty6WRN5WWRMjPz2fs2LGkpqZe9vcuXryYuro6HnnkkUbPlZyczP79+/Hy8mr0bV8uueeUhNuxYwdvvfUWZrMZNzc35s2bR+fOncnOzmbevHmYTCbsdjtjxowhJSWFzz77DLvdzp49exgxYgR33333ebe7cuVKli1bhk6nw263s3DhQhISEsjOzuaFF16gvLwci8XCHXfcwdixY3nmmWcAmDhxIlqtluXLl+Pj4+PIH8VvyD2nkzGZTBiNRkpLSyktLaW6uhqr1YrNZsNoNOLh4YGXlxdubm64uLig0+kIDg4mLCyM0NBQXF3V8Xr8y55z9erVPPTQQyxduhRvb28yMjKYMWMG27dv5/nnnyc4OJiZM2cCUFlZia+v7yXvObt168bmzZsJCQnBbDZjs9lwc3Nj/PjxLFiwgISEBGpqahg7dixvvvkmCQkJcs8pXZjNZiMnJ4f09HSOp6Vx6PAx8vLzKTcaqao8+0rv6eWDh94HVw8DWldP0GjRaFwozz1AtI+W2GBf7ApY7QoWOxjrLJyprqO82kSAr4GwkGDCIyIIbxVFRKtowsPDSUpKok2bNg4v786dO8nNzWXy5Mnn/s5qtVJaWsq1117LggULMJlM9OzZk169el3Wtnv16sWjjz7KoEGDGDhwIFFRUWRmZpKVlcXcuXPPPc5isZCdnU1CQkKjPa/GIMspkM1m48iRI+zZs4cDBw9zPC2NvNwc9N5+6P0i0HiGojOEoQtvR1CcgXB3A1o3DzQazXm3V1uazQ1JOsZ2CDvv1612BWOdmZIaM2dqCyjJyuHkERvf10NWWR1FlTVc0yaZ7j170+3aHnTp0oWwsPNvqzH169eP+fPn/+Hvhw0bRufOndm9ezfvvfcea9eu5ZVXXrnk7S5ZsoTDhw+zb98+pk6dytNPP01ERAT+/v785z//acyn0CRkOR1IURQyMjLYtWsXW7Zu58cfvsfdyw/PgETcfFrhEXcz7TqF4eLm0STju2o1hHi7E+LtTvvzfL26wcrx4hqOHtjM+99+wdGCcvR6PV26dKZ7r76kpKTQrl27C744XIm+ffuyZMkSMjIyzp25PXToEB07duTUqVNERUVxyy23EBMTw2OPPQaAt7c3xcXFF92u1WqloKCAjh070rFjR3Jzczl+/Dh9+/bFw8ODzz//nNGjRwOQlZVFaGgo3t7eeHl5UVNTo4rDWvmes4mZTCa2b9/OuvUb2L17N4rGBe+QZHT+iRhCk3Dz9G20sbK3PM+0dhfec14uRVHIr6znaHENx0obSM2vQufhxagxtzDqppuvqqi/Plu7a9cuFi1aRH19PRaLha5du/LPf/6Tt99+m40bN+Lm5oZGo2H27NkMGDCAvLw87r33XoALnhAym81MmzaN6upqNBoN4eHhvPTSS/j7+5OTk8MLL7xAYWEhdrudwMBAFi5cSEBAAEuWLGHjxo14eHjIE0LNkcViYdu2baxas47t27ZhCIrBPbgDPuHtcPcOarJxG7ucv6coCmlnatmeU8m2k5V46L0ZOXrMVRdVOj9ZzkZ05MgRVnz6GevXf467IQTPsC74tuqCm4fBIeM3dTl/7UJFnTBxEnFxcU0+fksgy3mV7HY733zzDa//6w1OnszBJ7onvtHX4mEIcXgWR5bz134p6rcnK/lvRhldu3bj7nvupW/fvk2+Nz1+/DiPPvroH/5+ypQpjBs3rknHbmqynFfIZDKxZs0aFi15k3qrKz5xA/GP6oJG6yIsk6hy/lq9xcbXGWWsPV6Om5cvM++9jzFjxqhiOpyzkeW8TGVlZSxd+j7vL/sQvX8MPvED8Q5urYr3W2oo5y8UReGHvEo+O1rO6Vobf/37/UyaNAlPT0/R0ZyGLOclMplMvPXW27z1zrv4RnbCP2EQHj7iS/Brairnrx0tqubjw2WklZqYdc/fmH7nXbi7u4uOpXqynH/Cbrezdu1ann3+Bdx8oglqOwp3Q7DoWOel1nL+IrO0ln/vP8Ppeheef2k+gwYNEh1J1eQkhIvYs2cP8x5/ivIaC0Gdb8c7SF3Tu5xNYpAXLw2NY09OOY/O/httO3bmuRdeJioqSnQ0VZIXW59Hfn4+kybfzvS7/4Y1qDfR/ebIYjaiPrH+LLslmZi6HIYNGcxrr5ydPyv9liznryiKwieffMJ1Q4aSXe5NwpDHCYjuroqTPc2Nu6uWO7qG8+8xyfy0aSUD+/Xl66+/Fh1LVeR7zv8pKCjgvtlzScvMJ6zLZDz9IkRHumxqf895Md/nVrAotYjEdh14bdESgoKabiaVs2jxe05FUVi9ejWDrruevBo/YgfMdcpiOrse0X58cEsSEXWnGHrdIPbu3Ss6knAt+oRQWVkZf79vDoeOZdCq91/R+8sTEyK5uWi5+9oIOoVWMGv6NKbPnMXf77sfrbZl7kNa5rMG9u/fz6Drriez1IWYAQ/KYqpIz2g/3hndmv+uXMbkCeMoKysTHUmIFldORVH48MOPmDhpCr7Jowm9ZjRalxZ9AKFKId7uLLwxgWhzAUMHD7qiG4E5uxZVTovFwgMPPszLr71BTP/Z+LXqJDqSdBGuWg0ze0TwQM8gZky7nUX/Wojdbhcdy2FaTDmNRiO3jB3Pt3uPEjtgDh4+oaIjSZeoV4w/79ycxKZPP+CemTMwm82iIzlEiyhnbm4u1w8bTnFDAK16zsDFTU6+djahBndeHx5PecYBpk+d0iImLTT7cmZmZjJi1M24R6QQes1NaFromb/mwN1Vy3ODY3ArO8mkcbdSVVUlOlKTata/qceOHePm0WPxSbiBwMT+ouNIjcDVRcvjA6KIUkq5dcxNzfpMbrMt58GDBxl76wT8291MQNzl3e9UUjetRsPs3pF082lgzKgRFBQUiI7UJJplOVNTU5kwaTJBHcfjH9VNdBypCWg0GmZ0j2BYK1fGjBpBdna26EiNrtmVc+/evdw+9S+EdZ2KX2RH0XGkJjapUyi3tTUwdvRNZGZmio7TqJpVOdPT05k2/S7Cu9+BT1gb0XEkBxnVNpg7OwUyecI4ioqKRMdpNM2mnIWFhYyfeBvB7UfLYrZAN7YJ4sY4PVMmjm82Z3GbRTmrq6sZP+E2PCN64R/TQ3QcSZApnUNpq2/gL7dPpr6+XnScq+b05TSbzUy9Yzr1bhEEJV8vOo4kkEajYUCsgR9+OsCsWffg7JcqO3U5FUXh/tlzyTljIrTjrfKOBS3cf9NLefjLdILbj+DHQ+kseeMN0ZGuilNfjvH22++wK/VnolPukzN/WjBFUXj/xwI+O1hAZK8Z+LXqhLmuN0veeI2k1q0ZNmyY6IhXxGl/ow8cOMBrCxcR3v0vaF3l3cRbKovNzrNbs1l9+Ayxgx85d6WRTu9PZM87uW/2XPLy8gSnvDJOWc7Kykqm3zWT0E7jcfcOFB1HEqS63srf/3Oc1AIzCTc8h96/1W++7hUYi3/CYO66exZWq1VQyivndIe1iqLw9/vn4OqfhH9UF9FxnNaGtDK+ySrnZHkDA+N8eaDv2V/sUxX1vLo7n8Lqs5dlJQZ4MqtHODF+51/Qd8yKY7/5b7PNzoikAO7p2bT3YSqorOe+DcdpcA8l4YYH0bqe/1c5KGkw+XtPsOCVV5n36CNNmqmxOV05P/zwQ/YfSiem/xzRUZxaoKcrEzuE8FNBDWbb/1/AHKh34/EB0YR4uWFX4It0Iy99l8dbN7U+73bW39bu3J9NFhu3rU6nX2zjLQh8PkeKqnnoizTcwzoR3+euiz5Wo9ES1mUyHyybz6CBA+jVy3nmWTvVYe2RI0f454vzCe8+Da2Lm+g4Tq1vjC99on3wcf/tqmjeOhdCvXXnznxrNZzbi/6ZXblV+Hm4cE2IvtHz/uLbzDLmbDiOd9INxPxJMX/h5ulLWJfbuHvWPZSXlzdZtsbmNHtOs9nMzFl/I+Sa0ULWvmxpbv30GCarHUWB2ztf2s97a1YF18X7NclHWoqi8PGBQj766TRh104jIKb7ZX2/b0R7TKXp3Dd7Lh8te98pPnZzmj3nkjfepNaulzOAHGTNpHasndiOe3qEkxDw53eOKK4xc7i4liEJ/o2exWqz8+L2HD4+UETMwAcuu5i/CGk/iv0Hj7F58+ZGTtg0nKKcWVlZvPX2O4R0HOcUr3jNhYeblhuTA3hlVz4Vpouf7fw2u4J2IXrCDI37sVZNg5XZX6SzM9dE/LCn8QqMveJtaV3cCO5wK/Mee5K6urrGC9lEVF9ORVGY88DDBCUPxd1LfmziaIoCDTY7pXWWiz5ua1YFQ+Ibd69ZXN3AXWuOkGPyInH4s+j0fle9TUNoEq6+sbz62sJGSNi0VF/ODRs2kH2qgMCEAaKjNCs2u4LZZseuKNiVs3+22RX2F9SQWWbCZleoNdt498dCvHUuRPtdeLHbY2fqKDVZ6Bfr02j50s/U8JdVhzEZWhM35LFGnWgS1P4mPvpoueqv/1T1CaHa2lqeeOppgjtOQaN1+fNvkC7Zp4fO8MmhknP//W12JZM7BhPj58Fb3xdQWmdF56IhOciT54fEonM5+zr+2eEzHC2u47khsee+95uscvpG+6B3a5x/o50njTy7JRPfxOuI7DymUbb5azpPP4KSh/LQI/NYt2aVat8qqbqcixYvQecXj3dIougozc6UzqFM6Xz+e/de7HPKiR1CoMNv/+6+3pGNlmvVz0W8l5pHSNfJBMX3brTt/l5g4gBObJvPl19+yciRI5tsnKuh2sNao9HI+x8sI7DNCNFRJAew2RVe3ZnD0h9OE9X//iYtJoBG60LwNWN54smnVXuTatWWc8kbb+HbqoucO9sC1FlsPPjlCb7JriFu6FMYHHSkZAhNQuMRyJo1axwy3uVSZTnLyspYvvxjAlvLi6ebu9JaMzPWHOVEtRuJw593+IuxX+JQFrz6OhbLxc9Gi6DKci5a/AZ+UV3ReQWIjiI1oczSWqatPEy1RwzxQ58Scumfd0giiqsv69evd/jYf0Z15SwpKeGTFSsISJJ7zeYsNbeCe9YfQxfdh7gBfxe6QK5f66HMf+V1bDabsAzno7pyLvzXYvyje6DTN/40MEkdPj96hie+yiCo4ziiuk4QHQfvkCQseLJhwwbRUX5DVeWsqalh5cqVBLQeLDqK1ATsisLi3bm8uTePVin3ENxaHevXaDQa/BKv56X5r6hq/U9VlXP9+vX4hCXLvWYz1GC1M++rDL48UU7ckMfwCWsrOtJvGMLaUmfWsGPHDtFRzlFNORVF4b2lyzBENe3nW5LjGevMzFx3lCNGLQnDn1flwsUajQbvqN68++8PREc5RzXl/PnnnykpK8cg79berJw01vGXVUcoc4kgftjTuOrUu3Cxf3R3fvg+VTWrlqmmnP9eugyf6N5oNKqJJF2ln/IrmbX2KNrw7sQPmiP0jOylcHHzwD+6Oys+/VR0FEAl5aysrGTzV5vwj5WHtM3FprQSHtmUjn/70URfO0V0nEtmiO7JihUrVXG3eFWUc+3adfhFtMfNwyA6inSVFEXhndR8Fu48Ras+swhtc53oSJdF7x+N2a7l+++/Fx1FHeVctWYdXuFykVtnZ7bZeWpLFuuPlhI7ZB6+EdeIjnTZNBoNXpHXsvxj8Ye2wstpNBo5kZ4mTwQ5uQqThXvWH+OnYhsJw5/F0zdcdKQr5teqK1u2bBE+Y0h4Obds2YJ/ZDt5q0snlldhYvrqIxQrwSQMfwZXd2/Rka6KzisAnd6XAwcOCM0hvJz/2bgJ96B2f/5ASZUOFVYxY80RlKBOxF/3EFqtqq/fv2QewW3579dbhGYQWk6TyUTqvr1O+d5Egi0ZpTywMQ3f5BFE95omOk6j8g5rz6bN/xWaQWg5d+7ciU9QtNMfBrU0iqKw7McC5m8/SXjPOwlrf4PoSI3OKyCO4uJiTp8+LSyD0HJu/HIzOnlI61QsNjvPf3uSzw4VEzv44Wa7mJRGq8Uvoj1bt24VlkFoOXft2o1BZROgpQurbrBy34Y09p5uIO6GZ9D7R4mO1KTcg9uy8cuvhI0vrJxFRUVUV1Xh4RMmKoJ0GQqq6pm++gh5Fh8SbngOnUfj3aNWrQwhyRzY/5Owy8iElfOHH37ANyxRzqV1AkeLq7lz9RHMfm1IGPLYBdfCbG7cPAy4uevJyckRMr6wZuxL/R4XQ7So4aVLtCPLyOz/HMcrYQixfe4WHcfhvAJi+Pnnn4WMLayc3/+4H31ArKjhpT+hKAorDhby/LdZhHWfSmTHm0RHEkLrHcmPP+0XM7aIQa1WK5kn0vBs5icUnJXVrjB/Rw4f/lRI9IA5BMS23GUX9QEx/PCjmJlCQt48ZGZmovcOwFXXdCsgS1em1mxl3lcZZJbbiR/2jxZ/yxhP/yjS96ZhtVpxdfB7bSF7zvT0dDz9G299DalxnF1y7yhZtXoShj/X4osJ4KrT4+ntT0ZGhsPHFlLO3Nxc0Ml/eDU5UVLL9NWHqfNKIP76x4Xc4Fmt9P6tOHHihMPHFXJYeyIzG1e9vJu7WuzOKefprzPwSRxEq85jRcdRHzdfIdP4hJTz5MlTuHtfK2Jo6XfWHC7inb15hHSdRFB8X9FxVEnr4Uf2yVOOH9fhIwL5+XnovINEDC39j82u8PquU7ybepqo/vfJYl6ETh9ATm6ew8d1+J7TarViLCshUh7WCmOy2Hjy60yOlpiJG/okHvKF8qJ0XgGcTm8Bh7UFBQV4GfzQurSMKWBqU1prZs7GNIw2L+KHP4mrm4foSKqn0wdw6kyRw8d1+GHt6dOn8ZAL4gqRXVbH9FWHqXCPIn7YP2QxL5GLTo/NZqWqqsqh4zq8nDU1NbjIXwqH+z63glnrjuIW2Zv4Afer/gbPaqLRaPDyCaKwsNCh4zr82LKurg6Ni7ujh23RNh47w7925RDSaRzBrQeIjuOUXHWe1NTUOHZMh44G1NbWotHKO+05gl1ReHtfPp8fLaZVyt/wlRe2XzEXV3dqa2sdOqaQPaeilXvOptZgtfP0N1kcKKwjbsjjqlzZy5loXN2pq6tz6JhC9pxKM7l9olqVmyw88EU6xQ3uJAx/Tl5g0Ag0WldMJpNDx3R4S6pratHIPWeTya0w8ZdVh7F5tSL+htnN5j6ywmlcsFgsDh3S4f9yNdU1clJ1E/r8SDEBcb2J73G76CjNikajxWq1OnRMh5fTxcVFFcurNUfBnSZiqCoiODFFdJRmR2kJe05vbz12W4mjh20RDCGJGEISRcdonhQbOp1jj/gc/km0Xq8Hu9nRw0rS1bE14OXl5dAhHV5OT09PNHbHHrtL0tWyWxvw9nbssiFiyqk49thdkq6W3VrfMsqp2GU5JeditbSAcp59zynLKTkXq7kFlNNgMGAzO3YalCRdLXNDXfMvZ3h4OA215Y4eVpKumN1mxWJuwGAwOHRch5czIiKCmqoyORFBchrmOiP+AUG4uTn2aioh7zl1OndsZsdefiNJV6qhpoSoKMcvuiXkcviw8AgaakpFDC1Jl81cU0piQpzDxxVSzri4OBpq5BQ+yTnYTKUkJzl+WqSQcia1jscs95ySk1Dqy4mJiXH4uELK2ToxEeplOSXn0FBT0nLK2aFDB+rKc0UMLUmXRbHbqK44Q2xsrMPHFnNYm5SEqcaIVU5GkFTOVFlAaFiEw69IAUHldHV1JSm5HXVGufeU1K22NJuePcQsuiXszsI9e3TDVJ4janhJuiTWqlz69O4pZGxh5ezerSv26nxRw0vSJakty6Zbt25CxhZWzi5dulBVki2n8UmqZTFVYm2oIyEhQcj4wsoZGRmJi4sWc61RVARJuqjaspN06NhZ2Loywsqp0Wjol9KPqsKjoiJI0kXVG0+S0qeHsPGFLjU1auRwzGXHRUaQpAsylRxn4MCBwsYXWs6BAwdSUZSBzVIvMoYk/UFDdQk2Sx2dO3cWlkFoOQ0GA9d06Eh1cZrIGJL0B5UFh7lu8HVC1zEVvoLqzaNuxHRGvu+U1MVcepRRI4cLzSC8nEOHDqWy4AiK3S46iiQBYKmvorosjwEDxC40LLycUVFRBAUFUVt2UnQUSQKgIu8gAwYOxMPDQ2gO4eUEuG3ieKrzvxcdQ5IAaDhziFtvGS06hjrKOXHiBMrzDmCzOHZxUkn6vfqqYuqrChk8eLDoKOooZ3BwMH369KX81A+io0gtXEXOLm6bNAl3d/ELPKuinAB3Tb+DmvxU0TGkFsxuNVN+6gemTZsqOgqgonL269cPF6VeXuMpCVOe+xNdunQhKipKdBRAReXUarVMm3o7Vbl7REeRWqiavN3MuvtO0THOUU05ASZNmkh57gF5+xLJ4WqNp9DaTULn0v6eqsoZGhrK9UOvx5i5Q3QUqYWpPPkd06fdgYuLi+go56iqnAAPzLkfY/Z3cjK85DD1VUXUFB1j2rQ7REf5DdWVMzExkZS+fTFm7xQdRWohjCe+4p57/oqPj4/oKL+hunICPPzQXMoytsm9p9Tk6iryqSvNZMZd6jkR9AtVlrNt27b075dCWZZ87yk1rfL0r5h9371nV1xXGVWWE2Deow9hzNwmz9xKTabWeApzVR5Tp6pj0sHvqbaciYmJDB8+nNK0zaKjSM1UefpmHpw7B09PT9FRzkujqPjelEajkT4p/YnsNQu9vzpmbVyMpc5I8eH11FfkotG64B3WkZD2o9BoXVAUO2XpX1OZ9wN2awM6ryBa9Z6Ji9sffzFKjn1JdcFB7NZ6tG6e+Eb3IrC1+InYzUnF6UPUZ29i964d6HQ60XHOS9XlBPjkk094+fV3ie4/G41GtTt6APJTl+Lq7k1Ih1uwW+rJT30P3+ge+MelUJr2FabyU4R1Go+rpx/m6mLcvALRuvxxKXNzzRlcPfzQuuqwmCo5nfpvApOHYgjvIOBZNT82Sz3ZW1/k3+8sISUlRXScC1L3bzswadIkQgO9MJ7cKzrKn7KayvEO74jWxQ1XDwNewUmYq4uxmesoP7mL0I634qb3R6PR4O4Tdt5iAui8Q9C6/urVXKPBUlvmoGfR/JUe38SgASmqLiaAq+gAf0ar1fL6q/O55dYJ+EZ2wtXdW3SkC/KLS6G64Gf0QQnYzCZqS9IJTBpGQ3URGo2WmsJDlJ/cidbVA/+4FPxi+1xwW8bMbZRlbEWxmXHTB2CIFHcXuOakzphL1emf+OfK70RH+VOqLyfANddcw9ixY9iydyPhXSaJjnNBngFxVOamkvnVU6DY8WnVDe+w9ufeP5prS4kbPA9LbSn5+97FzSsIr+Ck824rIHEQ/gkDaagqoKboKC5uYm+Z0RwodhtnDq3kmX88SUBAgOg4f0r1h7W/eOzRR2goTaOqSJ230VQUO6e/X4p32DUk3vA8CUP/gc1iovT4JjTas4evga2HoHVxw90nHENEJ2rPXPy5aDQaPHwj0bq4UZq+xRFPo1krzfyOmMhgxo8fLzrKJXGachoMBt5Ysoii/R9jqa8SHecP7BYTVlMFfrF90Lq44qLzwjeqO7Ulabj7hJ99kObX36E532bOS1HsWOrke86rUV9VjPHE1yx8bQEazaX/7EVymnIC9O/fn9unTKJo/ycoirpupemi88JNH0DlqX0odhs2i4nKvJ9wN4Sj8wrEMyAOY8a32G1WGqqLqS44iHdo2z9sR1HsVJzah81ch6IomMpzqcjZgz4oUcCzah7sNguFP37IY/MeITHReX6Oqv8o5fcsFgsjRo2myjWe4OQhouP8Rn1lASVHN9BQXQho0AclEnLNzbi6G7CYKik+tBqTMQdXd2/8EwbiF9MLgKr8/RgztxE78IH/HR6/T31FHordhquHDz6tuhOQOMhpXvHVpujQWtqEa/noww+c6mfodOUEyMvLY8jQG4jseTdegbGi40gqVpF/kOoTG9n27Rb8/f1Fx7ksTnVY+4uoqChee2U+BT9+iM0sb6cpnV99VTHFB1ey7IN/O10xwUnLCTBixAhGDL+ewv0fodhtouNIKmOzNlDww/s8/tijQlcKuxpOeVj7C4vFwvgJt5FfqSO00zinej8hNR3FbuP09+/Tp0s8Sxb/y2l/L5y6nABVVVXcOOImbH4dCEpS1wkiyfEURaHo4EqiA+x8tmK5aie1XwqnPaz9hY+PDys/+4Sa3F1U5O0XHUcSrCTtK7wp4aNlS526mNAMygkQGRnJp58s58yhNdSUZImOIwlSlr0bS/F+Vn22Am9v9c7BvlTNopxwdv7tO2+/cfYzwqoi0XEkB6s8fZiKE1+xetWnhISEiI7TKJpNOQEGDhzIs888xaldS2RBW5DqMxkUHVjBx8uXkZCQIDpOo3GKq1Iux8QJZyc1P/X0c8Sk3IuHT5jgRFJTqiw4SvGBT3h/6bt07dpVdJxG5fRnay9k1arVPPmPZ4nq81c8/SJFx5GaQEXefkqOrOWT5R/SrVs30XEaXbMtJ8Dnn3/Ow48+QateM+Q0v2bGeHIvFSc2s2rlCtq3by86TpNo1uUE+Oabb7jn3vsJ7zYVn7A2ouNIjaA0Yxt1uTtZu2alU11lcrmafTkB9u7dy/Q778Y/aSiBCf1Fx5GukAbRF6YAAAgzSURBVKLYOXN8M/ayQ3y+bg2tWrUSHalJtYhyAuTk5HDblKmY3VsR2mEsWpdmdy6sWbOZTRTuX06Yn5aPlr1PcHCw6EhNrll9lHIxsbGxfP3VJpLD3cjb8waW+mrRkaRLZKosJGfHqwxJ6cB/1q9tEcWEFrTn/IXdbufl+Qv4cPmnRPa8yyluVt2Slecd4MzPq3j2mX8wceIE0XEcqsWV8xcbN27kgYceIbjtKPzjejvtlQvNlWK3U3L8C+qLD/LRsvfp1KmT6EgO12LLCZCWlsbds/5GtcWD0E4TcPP0FR1JAhpqSik+sIKYcF8+eP89AgMDRUcSosW85zyfNm3a8M3Xmxk3sh/Z375Mee5PoiO1aIqiUJa9m5PbX2XmtFtZv251iy0mtPA956/t37+fWff8HasuhNCO43B19xIdqUVpqC3jzM+r8PWw8u7bb5CcnCw6knAtes/5a127dmXHtm8Y1q892d++RHneAeTrVtNT7HZKM7ZxctsCpk0czjdfb5bF/B+55zyPvXv38uDD86gxuxLU7mb0AdGiIzVL1cXplB3bQFREAIsWvtasZ/tcCVnOC7DZbKxYsYIXX1qAPjiZwHYj0Xn6iY7VLJgqCig7vgGNuYynn3qCUaNGybPl5yHL+Seqq6t5feEili9fTkDCQIKSrvvt8nzSJTPXVVCWtpma4iPMnX0/d9wxFXd3d9GxVEuW8xLl5eXx1NPPsWfPXvwTBhEQ31eu/HWJLPXVGLO2U569iylTJjP7/vvw9ZUfW/0ZWc7LdOTIEV557V/s3r2bgPh+BCT0V/WaoSKZKgupyN5ORd4BRowYycMPzSUyUl5be6lkOa9QVlYWCxctYfOmTfhHd8U3bgCevuGiYwmnKArVRcepytlBQ2UB06ffwbQ77iAoKEh0NKcjy3mVSkpK+OCDZXzw4Ud4+ITjGdYVv6jOuLh5io7mUNaGGiryD1Cdswtfgwf33ftXRo8eLd9TXgVZzkZSX1/P1q1b+eTTVaTu24tfRHv0EV3xCWvXbC9Ps1nqqTj9M/VFB6ksziSlX3/u/MtU+vXrJ8++NgJZziZQXl7OF198wccrVpKdlYVfVFe8wjvhFRSP1sVNdLyrYreaqSw8iqnoIOUFR+nevQeTJtzK9ddf3yzuFasmQso5btw4zGYzFouFnJwcWrduDUC7du148cUXL2kbn376KQ0NDUybNq0Jk0J+fj67d+9mwoQru1wpNzeXNWvW8uXmr8nOysA/PBE3v0S8Q9vg6ReJRqPuSVqKYsdUcZqa4jQs5ZmUF2XS/pqO3DbxVoYPH+6Uq3c5C6F7zvz8fMaOHUtqauofvma1WnF1FX84mJqayssvv8y6deuueluVlZXs3buXrdu2s337d5SXl+MX3hZX31g8fSPx8IvAVadvhNRXzmquo76igNqybGzVp6goysDfP4CBA/oz5LpB9OnTBx8fH6EZWwpVlXPw4MHceOON7Nu3j6SkJObMmcPcuXOpra2loaGBAQMG8PDDDwOwePFi6urqeOSRR1i3bh1ffPEFPj4+ZGRkYDAYWLx48R+umLfb7Tz77LPs27cPnU6HXq/ns88+A2DHjh289dZbmM1m3NzcmDdvHp07d2bEiBHk5+cTGxtLTEwMixYtarTnf/r0aXbt2sWevakcPnqMnOxMdB5eePm3QqsPRWeIwMM3HJ3eDxedV6O9j1MUBWtDDfVVRdRXFWKrPYOtrpgaYwFWSz0xsQn07NmdlD696dGjR7O5g7qzEb9r+p2amhrWrFkDQENDA2+//TZeXl5YLBbuvPNOvvvuO/r3/+NNug4fPsyGDRsIDw/niSee4OOPP2bOnDm/eUxaWhqpqals2rQJrVZLZWUlcPbQ880332Tp0qV4e3uTkZHBjBkz2L59O0899VSj7Tl/LzIykgkTJpw7ZLbb7eTl5XH8+HGOHTvOwUNHyEj/jtySYsxmM16GANz1vmeL6qZHcfEEjQtwtrQKmv8VWAMaDditaGx1YK3DZq7FUl9Ng6kGU10VHh56omPj6N4mmQ7tU0hOTqZ169ZERETIkzkqobpyjh49+tyfbTYb8+fP58CBs1eIlJaWkpaWdt5ydu3alfDws58zdurUiT179vzhMVFRUVitVh5//HF69uzJoEGDANi5cye5ublMnjz53GOtViulpaWN/fQuSqvVEhMTQ0xMDDfccMNvvlZXV0dRURGlpaUYjUbKy8sxGo1YLBYURTn3P5vNhqKA3W5Dp9MRGBhIQEDAuf8PCAjA39/f6VfgaglUV069/v/fc33wwQdUVVWxevVq3N3defLJJ2loaDjv9/368zQXFxdstj+udm0wGPjyyy9JTU1lz549vPLKK6xfvx6Afv36MX/+/D98T1aWOlYt0+v1xMfHEx8fLzqK5CCqPlVYXV1NcHAw7u7uFBcXs3Xr1qvantFoxGQy0a9fPx588EEMBgN5eXn07duXnTt3kpGRce6xhw4dAsDb25uampqrGleSroTq9py/dvvtt3P//fczcuRIQkND6d2791Vtr7CwkCeffBKr1YrNZqN///507twZrVbLggULePzxx6mvr8disdC1a1c6duxIcnIycXFxjBw5kvj4+EY9ISRJFyMnIUiSSqn6sFaSWjJZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVIpWU5JUilZTklSKVlOSVKp/wPZyHmx9JTg7wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"GRVAC2SqGPSN"},"source":["# **II. Modelisation**"]},{"cell_type":"markdown","metadata":{"id":"0ZdpGyoOcpnq"},"source":["## Settings"]},{"cell_type":"code","metadata":{"id":"BcmCxMd8cr_3"},"source":["# Take a sample of the original dataframes\n","train_samp_df = train_df.sample(frac=0.001, random_state=1)\n","test_samp_df = test_df.sample(frac=0.001, random_state=1)\n","\n","# Set train and validation set \n","X = train_samp_df.drop('TARGET', axis=1)\n","targets = train_samp_df['TARGET']\n","\n","# Split the whole set\n","# The smallest part will be used to choose the best algorithm.\n","X_trainval, X_test, y_trainval, y_test = train_test_split(\n","    X,\n","    targets,\n","    test_size=0.2,\n","    random_state=1)\n","\n","# Split the trainval set\n","# The smallest part will be used for the validation phase.\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_trainval,\n","    y_trainval,\n","    test_size=0.2,\n","    random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsHeEDbASX6r"},"source":["## Fonctions"]},{"cell_type":"code","metadata":{"id":"8kV0HtGEr6zg"},"source":["def split_oversample_fit(X, y, model):\n","    '''\n","    Perform split, oversampling and fitting on the given X and y sets\n","    '''\n","    # Train / test split\n","    X_train, X_val, y_train, y_val = train_test_split(X,\n","                                                      y,\n","                                                      test_size=0.2,\n","                                                      random_state=1)\n","    # Oversampling\n","    X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n","    X_resampled = pd.DataFrame(data=X_resampled,\n","                               columns=X.columns)\n","    #X_resampled['TARGET'] = pd.Series(y_resampled)\n","    # Fit the model\n","    model.fit(X_resampled, y_resampled)\n","\n","    return model, X_val, y_val\n","\n","\n","def class_model_perf(X, targets, model):\n","    '''\n","    Designed for a binary classification, two categories in total.\n","    Important: the model must be already instantiated.\n","    '''\n","\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","\n","    # Accuracy\n","    accuracy = round(model.score(X_val, y_val), 3)\n","    \n","    # Confusion matrix elements\n","    y_pred = model.predict(X_val)\n","    # Get the false predictions\n","    pred_dict = dict(pd.Series(y_val - y_pred).value_counts())\n","    if -1.0 in pred_dict.keys():\n","        n_FP = pred_dict[-1.0]\n","    else:\n","        n_FP = 0\n","    if 1.0 in pred_dict.keys():\n","        n_FN = pred_dict[1.0]\n","    else:\n","        n_FN = 0\n","    # Get the true predictions\n","    temp_dict = dict(pd.Series(2 * y_val - y_pred).value_counts())\n","    if 1.0 in temp_dict.keys():\n","        n_TP = temp_dict[1.0]\n","    else:\n","        n_TP = 0\n","    \n","    try:\n","        # Precision\n","        precision = round(n_TP / (n_TP + n_FP), 4)\n","\n","        # Recall\n","        recall = round(n_TP / (n_TP + n_FN), 4)\n","    except ZeroDivisionError:\n","        return 'n_FP: {}, n_FN: {}, n_TP: {}.'.format(n_FP, n_FN, n_TP)\n","\n","    # f1 score\n","    f1 = round(f1_score(y_val, y_pred), 4)\n","\n","    return 'Accuracy: {}, Precision: {}, Recall: {}, f1-score: {}'.format(\n","        accuracy, precision, recall, f1)\n","\n","\n","def list_sample(my_list, chunk):\n","    '''\n","    Let a list be given, we select every 'chunk' element.\n","    Return a list of the selected elements.\n","    '''\n","    y = zip(*[iter(my_list)]*chunk)\n","    return [element[0] for element in y]\n","\n","\n","def plot_precision_recall_curve(model, X, targets, chunk=1):\n","    '''\n","\n","    '''\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    \n","    precision, recall, threshold = precision_recall_curve(\n","        y_val,\n","        model.predict_proba(X_val)[:, 1])\n","    f1_score = 2 * precision * recall / (precision + recall)\n","    # In the cas of overlapping points, select a sample of the lists\n","    precision = list_sample(precision, chunk)\n","    precision = np.array(precision)\n","    recall = list_sample(recall, chunk)\n","    recall = np.array(recall)\n","    f1_score = list_sample(f1_score, chunk)\n","    f1_score = np.array(f1_score)\n","    max_f1 = round(max(f1_score), 3)\n","\n","    plt.figure(figsize=(8, 8))\n","    plt.xlabel('Precision')\n","    plt.ylabel('Recall')\n","    close_default = np.argmin(np.abs(threshold - 0.5))\n","    plt.scatter(precision,\n","                recall,\n","                s=f1_score*2000,\n","                c=f1_score,\n","                cmap='Reds_r',\n","                edgecolors='k',\n","                alpha=0.5,\n","                label='Max f1_score: {}'.format(max_f1))\n","    plt.plot(precision[close_default//chunk-1],\n","            recall[close_default//chunk-1],\n","            '^',\n","            c='k',\n","            markersize=10,\n","            label='Threshold: 0.5',\n","            fillstyle='none',\n","            mew=2)\n","    # ADDITIONAL curves\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    # Line of equation y = x\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.legend(loc='best')\n","    plt.axis('square')\n","\n","\n","# Faire en sorte que targets et y_pred puissent être soustrait l'un à l'autre \n","# quelque soit leur type\n","\n","def check_prediction_costs():\n","    '''\n","    1. Check inputs of prediction_costs.\n","    2. \n","    '''\n","\n","\n","def prediction_costs(model, X, targets, y_pred=None):\n","    '''\n","    Return the sum of: \n","    - the cost of false positives,\n","    - the cost of false negatives.\n","    '''\n","    # Add the prediction errors to the original dataframe\n","    if type(y_pred) in [list, type(pd.DataFrame()), type(pd.Series())]:\n","        y_pred = np.array(y_pred)\n","    if not y_pred.any():\n","        y_pred = model.predict(X)\n","    targets = np.array(targets)\n","    targets = targets.reshape((-1,1))\n","    y_pred = y_pred.reshape((-1,1))\n","    X['Prediction error'] = targets - y_pred\n","    # Create a new feature, multiplying the difference by a money feature.\n","    # This will be choosen based on feature importances.\n","    # FP costs\n","    # log_AMT_ANNUITY_prev: Annuity of previous application\n","    # AMT_CREDIT_SUM_DEBT: Current debt on Credit Bureau credit.\n","    # Although useful, it is absent of test set, thus cannot be used. \n","    FP_list = []\n","    for i, row in X.iterrows():\n","        if X['Prediction error'].loc[i] == -1:\n","            FP_list.append(-X['Prediction error'].loc[i] *\n","                           X['log_AMT_ANNUITY_prev'].loc[i])\n","    FP_sum = sum(FP_list)\n","    # FN costs\n","    # log_AMT_ANNUITY: Loan annuity\n","    FN_list = []\n","    for i, row in X.iterrows():\n","        if X['Prediction error'].loc[i] == 1:\n","            FN_list.append(X['Prediction error'].loc[i] *\n","                           X['log_AMT_ANNUITY'].loc[i])\n","    FN_sum = sum(FN_list)\n","    # Remove the temporary column from X\n","    X.drop('Prediction error', axis=1, inplace=True)\n","\n","    return FP_sum + FN_sum\n","\n","\n","def costs_estimation(model, X, targets, chunk=1):\n","    '''\n","    Evaluate the cost for different values of threshold\n","    '''\n","    # Prepare for y_pred computation\n","    pred_proba = model.predict_proba(X)\n","    predict = [element[1] for element in pred_proba]\n","    precision, recall, thresholds = precision_recall_curve(\n","        targets,\n","        model.predict_proba(X)[:, 1])\n","    \n","    # In the cas of overlapping points, select a sample of the lists\n","    precision = list_sample(precision, chunk)\n","    precision = np.array(precision)\n","    recall = list_sample(recall, chunk)\n","    recall = np.array(recall)\n","    thresholds = list_sample(thresholds, chunk)\n","    thresholds = np.array(thresholds)\n","\n","    # Evaluate costs for different values of threshold\n","    y_costs = []\n","    for threshold in list(thresholds):\n","        # Compute y_pred\n","        y_pred = []\n","        for element in predict:\n","            if element >= threshold:\n","                y_pred.append(1)\n","            else:\n","                y_pred.append(0)\n","        # Compute the costs\n","        y_costs.append(prediction_costs(model,\n","                                        X,\n","                                        targets,\n","                                        y_pred))\n","\n","    # Set the 3 lists at the same size\n","    precision = list(precision)\n","    recall = list(recall)\n","    thresholds = list(thresholds)\n","    temp_min = min(len(precision), len(recall), len(thresholds), len(y_costs))\n","    precision = precision[:temp_min]\n","    recall = recall[:temp_min]\n","    thresholds = thresholds[:temp_min]\n","    y_costs = y_costs[:temp_min]\n","    return precision, recall, y_costs, thresholds\n","\n","\n","def costs_curve(model, X, targets, chunk=1):\n","    '''\n","    Display the precision / recall curve, the size and color of each point\n","    representing its corresponding cost.\n","    '''\n","    \n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    # get the \n","    precision, recall, y_costs, thresholds = costs_estimation(model,\n","                                                              X_val,\n","                                                              y_val,\n","                                                              chunk=chunk)\n","    # Plot the graph\n","    plt.figure(figsize=(8, 8))\n","    plt.xlabel('Precision')\n","    plt.ylabel('Recall')\n","    thresholds = [element - 0.5 for element in thresholds]\n","    close_default = np.argmin(np.abs(thresholds))\n","    plt.scatter(precision,\n","                recall,\n","                s=y_costs,\n","                c=y_costs,\n","                cmap='Reds',\n","                edgecolors='k',\n","                alpha=0.5)\n","    plt.plot(precision[close_default//chunk-1],\n","            recall[close_default//chunk-1],\n","            '^',\n","            c='k',\n","            markersize=10,\n","            label='Threshold: 0.5',\n","            fillstyle='none',\n","            mew=2)\n","    # Line of equation y = x\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.legend(loc='best')\n","    plt.axis('square')\n","\n","\n","def plot_ROC_curve(model, X, targets):\n","    '''\n","\n","    '''\n","    fpr, tpr, threshold = roc_curve(targets,\n","                                    model.predict_proba(X)[:, 1])\n","    plt.xlabel('FPR')\n","    plt.ylabel('TPR (recall)')\n","    plt.title('ROC curve')\n","    # Line of equation y = x\n","    x = list(range(0, 100))\n","    x = [element/100 for element in x]\n","    plt.plot(x, x, color='k', linewidth=1)\n","    plt.axis('square')\n","    plt.plot(fpr, tpr)\n","\n","\n","def lowest_costs_param(model, X, targets):\n","    '''\n","    Return the lowest cost obtained.\n","    '''\n","    precision, recall, costs, thresholds = costs_estimation(model,\n","                                                            X,\n","                                                            targets)\n","    precision = [round(element, 2) for element in precision]\n","    recall = [round(element, 2) for element in recall]\n","    thresholds = [round(element, 3) for element in thresholds]\n","    costs = [round(element, 3) for element in costs]\n","    df = pd.DataFrame({'Precision':precision,\n","                    'Recall':recall,\n","                    'Cost':costs,\n","                    'Threshold':thresholds})\n","    df.sort_values(by='Cost', inplace=True)\n","    return dict(df.iloc[0])\n","\n","\n","def plot_feature_importances(model, X, n_feat):\n","    '''\n","    Display a histogram of the feature importances, sorted from the most\n","    important to the least important.\n","    '''\n","    feature_importances = pd.Series(model.feature_importances_,\n","                                    index=X.columns)\n","    feature_importances = feature_importances.sort_values(ascending=False)\n","    feature_importances = feature_importances[:n_feat]\n","    plt.bar(range(len(feature_importances)),\n","            feature_importances,\n","            edgecolor='k')\n","\n","\n","def feature_importance_cumsum(model, df, filter=None):\n","    '''\n","\n","    '''\n","    importances = model.feature_importances_\n","    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n","                 axis=0)\n","    forest_importances = pd.Series(importances,\n","                                   index=X.columns)\n","    forest_importances.sort_values(ascending=False,\n","                                   inplace=True)\n","    if filter:\n","        # Sort and filter the first 10% \n","        ratio = len(forest_importances)//10\n","        forest_importances = forest_importances[:ratio]\n","        forest_importances\n","    plt.plot(forest_importances.cumsum())\n","\n","\n","def most_important_features(model, X, n_feat=6):\n","    '''\n","    Display the n most important feature.\n","    '''\n","    feature_importances = pd.Series(model.feature_importances_,\n","                                    index=X.columns)\n","    feature_importances = feature_importances.sort_values(ascending=False)\n","    feature_importances = feature_importances[:n_feat]\n","    return feature_importances\n","\n","\n","def plot_important_features(feature_importances):\n","    '''\n","    \n","    '''\n","    plt.barh(feature_importances.index,\n","             feature_importances)\n","\n","\n","def prediction_with_threshold(predict_proba, threshold=0.5):\n","    '''\n","    \n","    '''\n","    # Select positive prediction\n","    predict_proba = predict_proba[:, 1]\n","    # Form the y_pred\n","    y_pred = []\n","    for element in predict_proba:\n","        if element >= threshold:\n","            y_pred.append(1)\n","        else:\n","            y_pred.append(0)\n","    y_pred = pd.Series(data=y_pred)\n","    return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nIxkrBLQ_C-Y"},"source":["## A. Dummy classifier"]},{"cell_type":"code","metadata":{"id":"8HneCt6_1yCK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571583047,"user_tz":-120,"elapsed":13,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"cc5c9060-225a-4f4f-feec-795036fb131c"},"source":["# Instanciation\n","model = DummyClassifier(strategy='constant', constant=1)\n","# Scores\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Accuracy: 0.048, Precision: 0.0484, Recall: 1.0, f1-score: 0.0923'"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"wak84paR_HJF"},"source":["## B. Decision tree"]},{"cell_type":"code","metadata":{"id":"LPFCqI4F_Pdi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571583047,"user_tz":-120,"elapsed":11,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"fdec8e7a-1afd-4394-f168-841c997b6ed4"},"source":["# Instanciation\n","model = DecisionTreeClassifier(max_depth=2)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Accuracy: 0.581, Precision: 0.0741, Recall: 0.6667, f1-score: 0.1333'"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"5Ijwl1NGJCzB"},"source":["## C. Logistic regression"]},{"cell_type":"code","metadata":{"id":"qYv199nAJDT1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571583048,"user_tz":-120,"elapsed":10,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"25f6376f-a1e9-4610-cb6f-1fcde9e118cd"},"source":["# Accuracy score\n","model = LogisticRegression(C=0.1)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'n_FP: 0, n_FN: 3, n_TP: 0.'"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"4288fym__HS7"},"source":["## D. SVC"]},{"cell_type":"code","metadata":{"id":"a_YN995I_P0Q"},"source":["if False:\n","    # Instanciation\n","    model = SVC(gamma=0.05)\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyhma-mO_QGr"},"source":["## E. Random forest"]},{"cell_type":"code","metadata":{"id":"W3fbBQB2_XGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630571583459,"user_tz":-120,"elapsed":419,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"41ca3c86-348d-42ca-94a0-54fe114d40c7"},"source":["# Instanciation\n","model = RandomForestClassifier(n_estimators=100,\n","                               random_state=0,\n","                               max_features=2)\n","# Evaluation\n","class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Accuracy: 0.935, Precision: 0.0, Recall: 0.0, f1-score: 0.0'"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"e7m1W6csLXGq"},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYR5TDdDAvon"},"source":["# Costs curve\n","if False:\n","    costs_curve(model, X, targets, chunk=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRsnIFnmHcvg"},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWAnwjyCZkjW"},"source":["# Feature importances\n","if False:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_aiNsHr8J9Ok"},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TubExPZbZkUz"},"source":["# Feature importances: first ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSgZoJk9Ms-W"},"source":["# ROC curve\n","if False:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ZoCPqxH99XG"},"source":["## F. GradientBoosting"]},{"cell_type":"code","metadata":{"id":"_92yrB09-Ta6"},"source":["if False:\n","    # Instanciation\n","    model = GradientBoostingClassifier()\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LD2TyRhTKzbI"},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKp44h20FZYP"},"source":["# Costs curve\n","if False:\n","    costs_curve(model, X, targets, chunk=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QYKkwJIpoow"},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG492qMQXTsD"},"source":["# Feature importances\n","if False:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGEW_xz_XTpp"},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pn_L0CukaSbk"},"source":["# Feature importances: first ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eORmWcjzRzvI"},"source":["# ROC curve\n","if False:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Rqli5Ni-Rfq"},"source":["## G. XGBoost"]},{"cell_type":"code","metadata":{"id":"KJX8t87X-Tyn"},"source":["if False:\n","    # Instanciation\n","    model = xgb.XGBClassifier()\n","    # Evaluation\n","    class_model_perf(X, targets, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHp2kEBzR1QG"},"source":["# Precision recall curve\n","if False:\n","    plot_precision_recall_curve(model, X, targets, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2B8ZvzHBFVzm"},"source":["# Costs curve\n","if False:\n","    costs_curve(model, X, targets, chunk=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8od1shxgDeSs"},"source":["# Lowest cost\n","if False:\n","    lowest_costs_param(model, X, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KpetlMjVM7R"},"source":["# Feature importances\n","if False:\n","    plot_feature_importances(model, X, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJRZaUuTWnPk"},"source":["# Feature importances: cumulated sum\n","if False:\n","    feature_importance_cumsum(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhdIwzunYMas"},"source":["# Feature importances: most important ones\n","if False:\n","    plot_important_features(model, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrpHKuogR1Ng"},"source":["# ROC curve\n","if False:\n","    model, X_val, y_val = split_oversample_fit(X, targets, model)\n","    plot_ROC_curve(model, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K--exfDtsaaU"},"source":["# **III. Algorithm optimisation**"]},{"cell_type":"markdown","metadata":{"id":"G1zGw07MolK1"},"source":["## 0. Introduction"]},{"cell_type":"markdown","metadata":{"id":"sR5L39engzp4"},"source":["As XGBoost has been chosen, we need now to define the **objective function**.\n","\n","Objective function = Training loss + Regularization.\n","The general principle is that we want a *simple* and *predictive* model.\n","\n","**Training loss**\n","*   measures how predictive our model is with respect to the training data\n","*   obtained through prediction_costs\n","\n","**Regularization**\n","*   controls the complexity of the model,  helps to avoid overfitting\n","*   \n","\n","**Challenges ahead**\n","*   get similar performances on train set & test set\n","*   taking into account a *balanced* train set and an *imbalanced* test set.\n","*   big computation time (150 sec for a single 3-fold cross validation)"]},{"cell_type":"code","metadata":{"id":"kNwAxxfvg2Bg"},"source":["# Create a specific cost score\n","# cost_score = make_scorer(prediction_costs_for_cv, greater_is_better=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3HnzWelzr3q2"},"source":["## A. GridSearchCV"]},{"cell_type":"code","metadata":{"id":"EhH4DoNAacjb"},"source":["def CV_cost(X, targets, eta, gamma, max_depth, reg_lambda, n_splits=3):\n","    '''\n","    Perform a cross validation on train set and returns an average cost.\n","    '''\n","    # Guarantee a k-fold cross validation\n","    skfold = StratifiedKFold(n_splits=n_splits)\n","    # Create the list of costs for each fold\n","    train_costs = []\n","    test_costs = []\n","    for fold, (trainval_index, test_index) in enumerate(skfold.split(X, targets), 1):\n","        # Form trainval and test sets\n","        X_trainval = X.iloc[trainval_index]\n","        y_trainval = targets.iloc[trainval_index]\n","        X_test = X.iloc[test_index]\n","        y_test = targets.iloc[test_index]\n","        # Rebalance the dataset with SMOTE oversampling\n","        sm = SMOTE()\n","        X_trainval_oversampled, y_trainval_oversampled = sm.fit_sample(X_trainval,\n","                                                                    y_trainval)\n","        X_trainval_oversampled = pd.DataFrame(\n","            data=X_trainval_oversampled,\n","            columns=X_trainval.columns)\n","        y_trainval_oversampled = pd.DataFrame(\n","            data = y_trainval_oversampled,\n","            columns=['Targets'])\n","        # Instantiate and fit the model to trainval set\n","        model = xgb.XGBClassifier(random_state=0,\n","                                  eta=eta,\n","                                  gamma=gamma,\n","                                  max_depth=max_depth,\n","                                  reg_lambda=reg_lambda)\n","        model.fit(X_trainval_oversampled,\n","                y_trainval_oversampled)\n","        # Get the threshold giving the lowest cost\n","        threshold = lowest_costs_param(model,\n","                                    X_trainval_oversampled,\n","                                    y_trainval_oversampled)['Threshold']\n","        # Get predictions on test set\n","        train_y_pred = prediction_with_threshold(model.predict_proba(X_trainval_oversampled),\n","                                                 threshold)\n","        test_y_pred = prediction_with_threshold(model.predict_proba(X_test),\n","                                                threshold)\n","        # Display the results\n","        train_costs.append(prediction_costs(model,\n","                                            X_trainval_oversampled,\n","                                            y_trainval_oversampled,\n","                                            train_y_pred))\n","        test_costs.append(prediction_costs(model,\n","                                           X_test,\n","                                           y_test,\n","                                           test_y_pred))\n","    # Computation of the average values\n","    train_cost_avg = stat.mean(train_costs)\n","    test_cost_avg = stat.mean(test_costs)\n","\n","    return train_cost_avg, test_cost_avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXatz877sgGF"},"source":["# Set parameters range\n","eta_list = [0.1] # learning_rate\n","gamma_list = [0.05, 0.1, 0.2] # regularization term\n","max_depth_list = [2, 3, 4]\n","lambda_list = [1.2]\n","# alpha=[], # may be not used if tuning lambda is enough\n","scale_pos_weight = 1 # because of high class imbalance\n","objective = 'binary:logistic' # for classification problems with probability\n","num_feature = 100 # thanks to feature importance evaluation\n","\n","scores_df = pd.DataFrame(columns=['eta', 'gamma', 'max_depth', 'reg_lambda',\n","                                  'Train cost', 'Test cost'])\n","\n","for i, eta in enumerate(eta_list):\n","    row = {}\n","    row['eta'] = eta\n","    print('- ', i)\n","    for ii, gamma in enumerate(gamma_list):\n","        row['gamma'] = gamma\n","        print('--- ', ii)\n","        for iii, max_depth in enumerate(max_depth_list):\n","            row['max_depth'] = max_depth\n","            print('------ ', iii)\n","            for iv, reg_lambda in enumerate(lambda_list):\n","                row['reg_lambda'] = reg_lambda\n","                print('--------- ', iv)\n","                train_cost_avg, test_cost_avg = CV_cost(\n","                    X, targets,\n","                    eta, gamma, max_depth, reg_lambda)\n","                row['Train cost'] = train_cost_avg\n","                row['Test cost'] = test_cost_avg\n","                scores_df.loc[scores_df.shape[0]] = row"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hxsPVaIy3qW"},"source":["scores_df.sort_values(by='Test cost', ascending=True, inplace = True)\n","scores_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjaqjMXcE5po"},"source":["scores_df.to_csv(PATH + 'data/' + 'scores.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Z3EyRoU6oYu"},"source":["train_list = list(scores_df['Train cost'])\n","test_list = list(scores_df['Test cost'])\n","\n","plt.title('Train / test performances')\n","plt.ylabel('Cost')\n","plt.plot(train_list, label='Train')\n","plt.plot(test_list, label='Test')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hr4DZ8kWm-Hv"},"source":["# Plot design of experiment results\n","#eta_df = scores_df.groupby(by=['eta']).mean()['Test cost']\n","#eta_df.index = ['min', 'med', 'max']\n","gamma_df = scores_df.groupby(by=['gamma']).mean()['Test cost']\n","gamma_df.index = ['min', 'med', 'max']\n","max_depth_df = scores_df.groupby(by=['max_depth']).mean()['Test cost']\n","max_depth_df.index = ['min', 'med', 'max']\n","#reg_lambda_df = scores_df.groupby(by=['reg_lambda']).mean()['Test cost']\n","#reg_lambda_df.index = ['min', 'med', 'max']\n","\n","plt.title('Step 3')\n","plt.xlabel('Parameter values')\n","plt.ylabel('Test score')\n","#plt.plot(eta_df, label='eta')\n","plt.plot(gamma_df, label='gamma', color='orange')\n","plt.plot(max_depth_df, label='max_depth', color='green')\n","#plt.plot(reg_lambda_df, label='reg_lambda', color='red')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FU5Oeag-r7EP"},"source":["## B. RandomizedSearchCV"]},{"cell_type":"code","metadata":{"id":"L-_P_YZvotps"},"source":["if False:\n","    # Set parameters range\n","    RS_parameters = {'n_estimators':[80, 120],\n","                    'max_depth':[3, 7],\n","                    'max_features':[int(math.sqrt(X_train.shape[0])) + 20,\n","                                    int(math.sqrt(X_train.shape[0])) - 20],\n","                    'min_samples_split':[3, 7],\n","                    'min_samples_leaf':[1, 3],\n","                    'bootstrap':[True, False]}\n","    # Cross validation\n","    rdm = RandomizedSearchCV(model,\n","                            RS_parameters,\n","                            cv=5,\n","                            n_iter=10,\n","                            scoring=cost_score)\n","    # Fit the model\n","    rdm.fit(X_train, y_train)\n","    # Get the best parameters combination\n","    rdm_best = rdm.best_estimator_\n","    # Get the lowest cost\n","    cost = prediction_costs_for_cv(y_val, rdm_best.predict(X_val))\n","    cost = round(cost, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fasuEW5v5PiB"},"source":["# IV. pickle optimised model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pG4Qk9FP5V0R","executionInfo":{"status":"ok","timestamp":1630593256615,"user_tz":-120,"elapsed":11552,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"98abc49d-fb10-45f6-b25e-476fd7934bb8"},"source":["# Set train and validation set \n","X = train_df.drop('TARGET', axis=1)\n","targets = train_df['TARGET']\n","\n","# Oversampling the whole train set\n","sm = SMOTE()\n","X_train_oversampled, y_train_oversampled = sm.fit_sample(X,\n","                                                         targets)\n","X_train_oversampled = pd.DataFrame(data=X_train_oversampled,\n","                                   columns=X.columns)\n","y_train_oversampled = pd.DataFrame(data = y_train_oversampled,\n","                                   columns=['Targets'])"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mj3RjRlh7m4l","executionInfo":{"status":"ok","timestamp":1630594431575,"user_tz":-120,"elapsed":849858,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}},"outputId":"298dcb4f-f341-419f-dadc-ffebd79032db"},"source":["# Instantiate and fit the model to train set\n","model = xgb.XGBClassifier(random_state=0,\n","                          eta=0.1,\n","                          gamma=0.2,\n","                          max_depth=4,\n","                          reg_lambda=1.2,\n","                          scale_pos_weight = 1,\n","                          objective = 'binary:logistic',\n","                          num_feature = 100)\n","model.fit(X_train_oversampled,\n","          y_train_oversampled)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, eta=0.1, gamma=0.2,\n","              learning_rate=0.1, max_delta_step=0, max_depth=4,\n","              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n","              nthread=None, num_feature=100, objective='binary:logistic',\n","              random_state=0, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=1,\n","              seed=None, silent=None, subsample=1, verbosity=1)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"wauWGC1D7jbx","executionInfo":{"status":"ok","timestamp":1630594454898,"user_tz":-120,"elapsed":210,"user":{"displayName":"Benoît DELORME","photoUrl":"","userId":"03178733258717085125"}}},"source":["# Pickle and save\n","pickle.dump(model, open( \"fitted_xgb.pkl\", \"wb\" ))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CCy-NJuANMK"},"source":[""],"execution_count":null,"outputs":[]}]}